import os
import sys
from typing import List
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from config import config
from models.embeddings import get_embedding_model

def load_and_split_document(file_path: str) -> List[Document]:
    """
    Load a document (PDF or TXT) and split it into chunks.
    """
    try:
        if file_path.lower().endswith('.pdf'):
            loader = PyPDFLoader(file_path)
        elif file_path.lower().endswith('.txt'):
            loader = TextLoader(file_path)
        else:
            raise ValueError(f"Unsupported file format: {file_path}")
            
        documents = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.CHUNK_SIZE,
            chunk_overlap=config.CHUNK_OVERLAP
        )
        
        chunks = text_splitter.split_documents(documents)
        return chunks
        
    except Exception as e:
        raise RuntimeError(f"Error processing document: {str(e)}")
def create_vector_store(chunks: List[Document], embedding_provider="huggingface"):
    """
    Create a FAISS vector store from document chunks.
    """
    try:
        embeddings = get_embedding_model(provider=embedding_provider)
        vector_store = FAISS.from_documents(chunks, embeddings)
        return vector_store
    except Exception as e:
        raise RuntimeError(f"Error creating vector store: {str(e)}")

def get_retriever(vector_store, k=3):
    """
    Get a retriever from the vector store.
    """
    return vector_store.as_retriever(search_kwargs={"k": k})
